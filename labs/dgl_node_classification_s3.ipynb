{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Classification with [Deep Graph Library (DGL)](https://docs.dgl.ai/index.html) for the graduate course \"[Graph Machine learning](https://github.com/zahta/graph_ml)\"\n",
    "##### by [Zahra Taheri](https://github.com/zahta), 06 June 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Tutorial Is Prepared Based on the Following References\n",
    "\n",
    "- [A Blitz Introduction to DGL](https://docs.dgl.ai/en/latest/tutorials/blitz/index.html)\n",
    "  \n",
    "- [User Guide](https://docs.dgl.ai/en/latest/guide/index.html#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Node Classification with GNN\n",
    "\n",
    "One of the most popular and widely adopted tasks on graph data is node\n",
    "classification, where a model needs to predict the ground truth category\n",
    "of each node. Before graph neural networks, many proposed methods are\n",
    "using either connectivity alone (such as DeepWalk or node2vec), or simple\n",
    "combinations of connectivity and the node's own features.  GNNs, by\n",
    "contrast, offers an opportunity to obtain node representations by\n",
    "combining the connectivity and features of a *local neighborhood*.\n",
    "\n",
    "[A paper by Kipf et.al.](https://arxiv.org/abs/1609.02907) is an example that formulates\n",
    "the node classification problem as a semi-supervised node classification\n",
    "task. With the help of only a small portion of labeled nodes, a graph\n",
    "neural network (GNN) can accurately predict the node category of the\n",
    "others.\n",
    "\n",
    "This tutorial will show how to build such a GNN for semi-supervised node\n",
    "classification with only a small number of labels on the Cora\n",
    "dataset,\n",
    "a citation network with papers as nodes and citations as edges. The task\n",
    "is to predict the category of a given paper. Each paper node contains a\n",
    "word count vector as its features, normalized so that they sum up to one,\n",
    "as described in Section 5.2 of [the paper](https://arxiv.org/abs/1609.02907)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Number of categories: 7\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\n",
    "print(\"Number of categories:\", dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DGL Dataset object may contain one or multiple graphs. The Cora\n",
    "dataset used in this tutorial only consists of one single graph.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we split the graph?\n",
    "\n",
    " <img src=\"./node_classification.png\" alt=\"app-screen\" width=\"900\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DGL graph can store node features and edge features in two\n",
    "dictionary-like attributes called ``ndata`` and ``edata``.\n",
    "In the DGL Cora dataset, the graph contains the following node features:\n",
    "\n",
    "- ``train_mask``: A boolean tensor indicating whether the node is in the\n",
    "  training set.\n",
    "\n",
    "- ``val_mask``: A boolean tensor indicating whether the node is in the\n",
    "  validation set.\n",
    "\n",
    "- ``test_mask``: A boolean tensor indicating whether the node is in the\n",
    "  test set.\n",
    "\n",
    "- ``label``: The ground truth node category.\n",
    "\n",
    "-  ``feat``: The node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features\n",
      "{'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False])}\n",
      "Edge features\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(\"Node features\")\n",
    "print(g.ndata)\n",
    "print(\"Edge features\")\n",
    "print(g.edata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Graph Convolutional Network (GCN)\n",
    "\n",
    "This tutorial will build a two-layer [Graph Convolutional Network\n",
    "(GCN)](http://tkipf.github.io/graph-convolutional-networks/). Each\n",
    "layer computes new node representations by aggregating neighbor\n",
    "information.\n",
    "\n",
    "To build a multi-layer GCN you can simply stack ``dgl.nn.GraphConv``\n",
    "modules, which inherit ``torch.nn.Module``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "\n",
    "# Create the model with given dimensions\n",
    "model = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGL provides implementation of many popular neighbor aggregation\n",
    "modules. You can easily invoke them with one line of code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the GCN\n",
    "\n",
    "Training this GCN is similar to training other PyTorch neural networks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata[\"feat\"]\n",
    "    labels = g.ndata[\"label\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    val_mask = g.ndata[\"val_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        # loss = F.cross_entropy(F.log_softmax(logits[train_mask], 1), labels[train_mask])\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(\n",
    "                \"In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})\".format(\n",
    "                    e, loss, val_acc, best_val_acc, test_acc, best_test_acc\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.945, val acc: 0.114 (best 0.114), test acc: 0.123 (best 0.123)\n",
      "In epoch 5, loss: 1.888, val acc: 0.416 (best 0.476), test acc: 0.433 (best 0.467)\n",
      "In epoch 10, loss: 1.802, val acc: 0.554 (best 0.554), test acc: 0.594 (best 0.594)\n",
      "In epoch 15, loss: 1.695, val acc: 0.636 (best 0.636), test acc: 0.664 (best 0.664)\n",
      "In epoch 20, loss: 1.566, val acc: 0.658 (best 0.658), test acc: 0.704 (best 0.704)\n",
      "In epoch 25, loss: 1.418, val acc: 0.700 (best 0.700), test acc: 0.739 (best 0.739)\n",
      "In epoch 30, loss: 1.257, val acc: 0.714 (best 0.714), test acc: 0.753 (best 0.753)\n",
      "In epoch 35, loss: 1.089, val acc: 0.728 (best 0.728), test acc: 0.763 (best 0.763)\n",
      "In epoch 40, loss: 0.925, val acc: 0.738 (best 0.738), test acc: 0.767 (best 0.767)\n",
      "In epoch 45, loss: 0.772, val acc: 0.752 (best 0.754), test acc: 0.772 (best 0.771)\n",
      "In epoch 50, loss: 0.636, val acc: 0.770 (best 0.770), test acc: 0.775 (best 0.775)\n",
      "In epoch 55, loss: 0.519, val acc: 0.772 (best 0.772), test acc: 0.778 (best 0.777)\n",
      "In epoch 60, loss: 0.423, val acc: 0.776 (best 0.776), test acc: 0.782 (best 0.782)\n",
      "In epoch 65, loss: 0.345, val acc: 0.778 (best 0.778), test acc: 0.777 (best 0.782)\n",
      "In epoch 70, loss: 0.282, val acc: 0.778 (best 0.780), test acc: 0.777 (best 0.776)\n",
      "In epoch 75, loss: 0.232, val acc: 0.784 (best 0.784), test acc: 0.777 (best 0.777)\n",
      "In epoch 80, loss: 0.193, val acc: 0.782 (best 0.786), test acc: 0.779 (best 0.778)\n",
      "In epoch 85, loss: 0.162, val acc: 0.784 (best 0.786), test acc: 0.778 (best 0.778)\n",
      "In epoch 90, loss: 0.137, val acc: 0.786 (best 0.786), test acc: 0.778 (best 0.778)\n",
      "In epoch 95, loss: 0.117, val acc: 0.784 (best 0.786), test acc: 0.778 (best 0.778)\n"
     ]
    }
   ],
   "source": [
    "model = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on GPU\n",
    "\n",
    "Training on GPU requires to put both the model and the graph onto GPU\n",
    "with the ``to`` method, similar to what you will do in PyTorch.\n",
    "```python\n",
    "\n",
    "   g = g.to('cuda')\n",
    "   model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes).to('cuda')\n",
    "   train(g, model)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
