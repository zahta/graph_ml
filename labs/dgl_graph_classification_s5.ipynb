{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Classification with [Deep Graph Library (DGL)](https://docs.dgl.ai/index.html) for the graduate course \"[Graph Machine learning](https://github.com/zahta/graph_ml)\"\n",
    "\n",
    "##### by [Zahra Taheri](https://github.com/zahta), 06 June 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Tutorial Is Prepared Based on the Following References\n",
    "\n",
    "- [A Blitz Introduction to DGL](https://docs.dgl.ai/en/latest/tutorials/blitz/index.html)\n",
    "  \n",
    "- [User Guide](https://docs.dgl.ai/en/latest/guide/index.html#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Graph Classification with GNN\n",
    "\n",
    "Graph classification or regression requires a model to predict certain\n",
    "graph-level properties of a single graph given its node and edge\n",
    "features.  Molecular property prediction is one particular application.\n",
    "\n",
    "This tutorial shows how to train a graph classification model for a\n",
    "small dataset from the paper [How Powerful Are Graph Neural\n",
    "Networks](https://arxiv.org/abs/1810.00826).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset with 10000 graphs, ranging from 10 to 500 nodes.\n",
    "dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a set of graphs, each with node features and a single\n",
    "label. One can see the node feature dimensionality and the number of\n",
    "possible graph categories of ``GINDataset`` objects in ``dim_nfeats``\n",
    "and ``gclasses`` attributes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature dimensionality: 3\n",
      "Number of graph categories: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Node feature dimensionality:\", dataset.dim_nfeats)\n",
    "print(\"Number of graph categories:\", dataset.gclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=40, num_edges=188,\n",
       "       ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
       "       edata_schemes={}),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1112]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we split the dataset?\n",
    "\n",
    " <img src=\"./graph_classification.png\" alt=\"app-screen\" width=\"900\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Data Loader\n",
    "--------------------\n",
    "\n",
    "A graph classification dataset usually contains two types of elements: a\n",
    "set of graphs, and their graph-level labels. Similar to an image\n",
    "classification task, when the dataset is large enough, we need to train\n",
    "with mini-batches. When you train a model for image classification or\n",
    "language modeling, you will use a ``DataLoader`` to iterate over the\n",
    "dataset. In DGL, you can use the ``GraphDataLoader``.\n",
    "\n",
    "You can also use various dataset samplers provided in\n",
    "[torch.utils.data.sampler](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler).\n",
    "For example, this tutorial creates a training ``GraphDataLoader`` and\n",
    "test ``GraphDataLoader``, using ``SubsetRandomSampler`` to tell PyTorch\n",
    "to sample from only a subset of the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * 0.8)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "train_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=5, drop_last=False\n",
    ")\n",
    "test_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=5, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to iterate over the created ``GraphDataLoader`` and see what it\n",
    "gives:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graph(num_nodes=133, num_edges=663,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), tensor([0, 0, 1, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each element in ``dataset`` has a graph and a label, the\n",
    "``GraphDataLoader`` will return two objects for each iteration. The\n",
    "first element is the batched graph, and the second element is simply a\n",
    "label vector representing the category of each graph in the mini-batch.\n",
    "Next, weâ€™ll talked about the batched graph.\n",
    "\n",
    "A Batched Graph in DGL\n",
    "----------------------\n",
    "\n",
    "In each mini-batch, the sampled graphs are combined into a single bigger\n",
    "batched graph via ``dgl.batch``. The single bigger batched graph merges\n",
    "all original graphs as separately connected components, with the node\n",
    "and edge features concatenated. This bigger graph is also a ``DGLGraph``\n",
    "instance (so you can\n",
    "still treat it as a normal ``DGLGraph`` object as in\n",
    "`here <2_dglgraph.ipynb>`__). It however contains the information\n",
    "necessary for recovering the original graphs, such as the number of\n",
    "nodes and edges of each graph element.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes for each graph element in the batch: tensor([20, 40, 10, 52, 11])\n",
      "Number of edges for each graph element in the batch: tensor([ 96, 200,  44, 268,  55])\n",
      "The original graphs in the minibatch:\n",
      "[Graph(num_nodes=20, num_edges=96,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=40, num_edges=200,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=10, num_edges=44,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=52, num_edges=268,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={}), Graph(num_nodes=11, num_edges=55,\n",
      "      ndata_schemes={'attr': Scheme(shape=(3,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})]\n"
     ]
    }
   ],
   "source": [
    "batched_graph, labels = batch\n",
    "print(\n",
    "    \"Number of nodes for each graph element in the batch:\",\n",
    "    batched_graph.batch_num_nodes(),\n",
    ")\n",
    "print(\n",
    "    \"Number of edges for each graph element in the batch:\",\n",
    "    batched_graph.batch_num_edges(),\n",
    ")\n",
    "\n",
    "# Recover the original graph elements from the minibatch\n",
    "graphs = dgl.unbatch(batched_graph)\n",
    "print(\"The original graphs in the minibatch:\")\n",
    "print(graphs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model\n",
    "------------\n",
    "\n",
    "This tutorial will build a two-layer [`]Graph Convolutional Network\n",
    "(GCN)](http://tkipf.github.io/graph-convolutional-networks/). Each of\n",
    "its layer computes new node representations by aggregating neighbor\n",
    "information. If you have gone through the\n",
    ":doc:`introduction <1_introduction>`, you will notice two\n",
    "differences:\n",
    "\n",
    "-  Since the task is to predict a single category for the *entire graph*\n",
    "   instead of for every node, you will need to aggregate the\n",
    "   representations of all the nodes and potentially the edges to form a\n",
    "   graph-level representation. Such process is more commonly referred as\n",
    "   a *readout*. A simple choice is to average the node features of a\n",
    "   graph with ``dgl.mean_nodes()``.\n",
    "\n",
    "-  The input graph to the model will be a batched graph yielded by the\n",
    "   ``GraphDataLoader``. The readout functions provided by DGL can handle\n",
    "   batched graphs so that they will return one representation for each\n",
    "   minibatch element.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata[\"h\"] = h\n",
    "        return dgl.mean_nodes(g, \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop\n",
    "-------------\n",
    "\n",
    "The training loop iterates over the training set with the\n",
    "``GraphDataLoader`` object and computes the gradients, just like\n",
    "image classification or language modeling.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.07623318385650224\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "model = GCN(dataset.dim_nfeats, 16, dataset.gclasses)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        pred = model(batched_graph, batched_graph.ndata[\"attr\"].float())\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata[\"attr\"].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print(\"Test accuracy:\", num_correct / num_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
